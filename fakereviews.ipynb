{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd2b502-5722-426c-b3b9-e1442abf5dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-23 13:15:10.979392: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-23 13:15:10.981298: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-23 13:15:11.012961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-23 13:15:11.012996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-23 13:15:11.013867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-23 13:15:11.019329: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-23 13:15:11.020548: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-23 13:15:11.747611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package punkt to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'data_preprocessing' from '/mnt/c/Users/mathan/Learning/Deep learning/FakeReviewsPrediction/data_preprocessing.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_preprocessing import load_and_preprocess_data, convert_to_embeddings\n",
    "import importlib\n",
    "import data_preprocessing\n",
    "\n",
    "importlib.reload(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76834cb9-09e1-411e-883a-a06855adf37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbdb38a-2e90-4439-9c3c-652c62a76588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/home/mathan/nltk_data')\n",
    "df = data_preprocessing.load_and_preprocess_data(\"fake reviews dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d792a320-7d92-41d2-8002-435e90649fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love well made sturdy comfortable love pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love great upgrade original mine couple years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>missing information use great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>nice set good quality set two months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3</td>\n",
       "      <td>CG</td>\n",
       "      <td>I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.</td>\n",
       "      <td>wanted different flavors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>They are the perfect touch for me and the only...</td>\n",
       "      <td>perfect touch thing wish little space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>3</td>\n",
       "      <td>CG</td>\n",
       "      <td>These done fit well and look great.  I love th...</td>\n",
       "      <td>done fit well look great love smoothness edges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Great big numbers &amp; easy to read, the only thi...</td>\n",
       "      <td>great big numbers easy read thing like size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>My son loves this comforter and it is very wel...</td>\n",
       "      <td>son loves comforter well made also baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5       5    CG   \n",
       "1  Home_and_Kitchen_5       5    CG   \n",
       "2  Home_and_Kitchen_5       5    CG   \n",
       "3  Home_and_Kitchen_5       1    CG   \n",
       "4  Home_and_Kitchen_5       5    CG   \n",
       "5  Home_and_Kitchen_5       3    CG   \n",
       "6  Home_and_Kitchen_5       5    CG   \n",
       "7  Home_and_Kitchen_5       3    CG   \n",
       "8  Home_and_Kitchen_5       5    CG   \n",
       "9  Home_and_Kitchen_5       5    CG   \n",
       "\n",
       "                                                text  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "5       I WANTED DIFFERENT FLAVORS BUT THEY ARE NOT.   \n",
       "6  They are the perfect touch for me and the only...   \n",
       "7  These done fit well and look great.  I love th...   \n",
       "8  Great big numbers & easy to read, the only thi...   \n",
       "9  My son loves this comforter and it is very wel...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0      love well made sturdy comfortable love pretty  \n",
       "1      love great upgrade original mine couple years  \n",
       "2            pillow saved back love look feel pillow  \n",
       "3        missing information use great product price  \n",
       "4               nice set good quality set two months  \n",
       "5                           wanted different flavors  \n",
       "6              perfect touch thing wish little space  \n",
       "7  done fit well look great love smoothness edges...  \n",
       "8        great big numbers easy read thing like size  \n",
       "9            son loves comforter well made also baby  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0359e32b-e9c7-4ffd-a692-b2a00afabc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = convert_to_embeddings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "195d5728-2d2a-456b-9c3e-e3b442447081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509a68db-a097-467e-bd73-ca64f1f8600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CG': 16200, 'OR': 16145}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c35b11-8de0-4950-a767-918e691b8e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    CG\n",
      "1    CG\n",
      "2    CG\n",
      "3    CG\n",
      "4    CG\n",
      "5    CG\n",
      "6    CG\n",
      "7    CG\n",
      "8    CG\n",
      "9    CG\n",
      "Name: label, dtype: object\n",
      "['CG' 'CG' 'CG' 'CG' 'OR' 'CG' 'OR' 'CG' 'OR' 'OR']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'][:10])  # First 10 rows of the original dataset\n",
    "print(y_train[:10])      # First 10 values of the encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b549ea06-57a4-4b5a-b89d-94b6bf94bdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05729083, -0.0597794 ,  0.02987007, ..., -0.04072677,\n",
       "         0.04173928, -0.03256984],\n",
       "       [-0.0536941 , -0.04432577,  0.0527682 , ...,  0.00398003,\n",
       "         0.06503216, -0.01011264],\n",
       "       [-0.01647874, -0.06732591,  0.06853691, ...,  0.03552276,\n",
       "         0.00350308, -0.02876311],\n",
       "       ...,\n",
       "       [-0.03296098, -0.06300158, -0.01281623, ..., -0.05929931,\n",
       "         0.03762821,  0.05196053],\n",
       "       [-0.01935246, -0.00717442, -0.05843958, ...,  0.05073142,\n",
       "         0.06015584, -0.00123711],\n",
       "       [-0.02783559, -0.03717551,  0.03088052, ..., -0.02095857,\n",
       "         0.00860633,  0.03128782]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47ec284-c083-4adc-b5d1-5d2593d6387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model using TensorFlow Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
    "    tf.keras.layers.Dropout(0.2),  # Dropout layer to reduce overfitting\n",
    "    tf.keras.layers.Dense(64, activation='relu'),  # Second hidden layer with 64 neurons\n",
    "    tf.keras.layers.Dropout(0.2),  # Another dropout layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "342fe032-1ece-4737-b5b8-42795e987f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer and binary crossentropy loss function\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9944ef17-9404-45fc-a4f3-1c89e837d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1011/1011 [==============================] - 4s 3ms/step - loss: 0.4716 - accuracy: 0.7632 - val_loss: 0.4137 - val_accuracy: 0.7983\n",
      "Epoch 2/5\n",
      "1011/1011 [==============================] - 3s 3ms/step - loss: 0.3958 - accuracy: 0.8115 - val_loss: 0.3855 - val_accuracy: 0.8149\n",
      "Epoch 3/5\n",
      "1011/1011 [==============================] - 4s 4ms/step - loss: 0.3547 - accuracy: 0.8354 - val_loss: 0.3732 - val_accuracy: 0.8223\n",
      "Epoch 4/5\n",
      "1011/1011 [==============================] - 4s 4ms/step - loss: 0.3206 - accuracy: 0.8548 - val_loss: 0.3743 - val_accuracy: 0.8235\n",
      "Epoch 5/5\n",
      "1011/1011 [==============================] - 4s 4ms/step - loss: 0.2918 - accuracy: 0.8712 - val_loss: 0.3761 - val_accuracy: 0.8290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdf10a69300>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for 5 epochs using batch size of 32\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c53b5bcc-a5e2-4fd5-a0b7-e4e3b74a23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathan/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model for later use\n",
    "model.save('fake_review_model_tf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db157de7-7871-4126-a74c-17f2cb93a695",
   "metadata": {},
   "source": [
    "### Test the created model with some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef52dadb-3c33-402f-b786-4967ed5bc1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-23 13:48:18.702863: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-23 13:48:18.704637: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-23 13:48:18.731832: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-23 13:48:18.731885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-23 13:48:18.732775: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-23 13:48:18.737664: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-23 13:48:18.737902: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-23 13:48:20.070739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package stopwords to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mathan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Review: This product is amazing! I would highly recommend it to everyone.\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Prediction: Fake\n",
      "\n",
      "Review: Worst experience ever. Total waste of money.\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction: Real\n",
      "\n",
      "Review: This is the best phone I've ever used. The camera is stunning!\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction: Real\n",
      "\n",
      "Review: I received this product for free in exchange for a review, and it's really great!\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Prediction: Real\n",
      "\n",
      "Review: I highly doubt this review is genuine. Seems very generic.\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prediction: Fake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 test_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab1368d-57d4-4fe8-afa8-b69e578c98fc",
   "metadata": {},
   "source": [
    "### Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb20fa5c-e973-402d-8aed-1be7faa9d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"fake_review_model_tf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61619f-6792-4a2c-9097-f559dd12c13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (WSL)",
   "language": "python",
   "name": "wsl_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
